{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9999110082762304,
  "eval_steps": 500,
  "global_step": 5618,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.017798344753937885,
      "grad_norm": 0.10990604758262634,
      "learning_rate": 1.9644001423994305e-05,
      "loss": 1.6985,
      "step": 100
    },
    {
      "epoch": 0.03559668950787577,
      "grad_norm": 0.1315210461616516,
      "learning_rate": 1.9288002847988608e-05,
      "loss": 1.6697,
      "step": 200
    },
    {
      "epoch": 0.05339503426181365,
      "grad_norm": 0.12449868023395538,
      "learning_rate": 1.8932004271982915e-05,
      "loss": 1.6455,
      "step": 300
    },
    {
      "epoch": 0.07119337901575154,
      "grad_norm": 0.12530916929244995,
      "learning_rate": 1.8576005695977218e-05,
      "loss": 1.6345,
      "step": 400
    },
    {
      "epoch": 0.08899172376968942,
      "grad_norm": 0.13259904086589813,
      "learning_rate": 1.822000711997152e-05,
      "loss": 1.6304,
      "step": 500
    },
    {
      "epoch": 0.1067900685236273,
      "grad_norm": 0.15248295664787292,
      "learning_rate": 1.7864008543965825e-05,
      "loss": 1.6283,
      "step": 600
    },
    {
      "epoch": 0.12458841327756519,
      "grad_norm": 0.14408637583255768,
      "learning_rate": 1.7508009967960128e-05,
      "loss": 1.6262,
      "step": 700
    },
    {
      "epoch": 0.14238675803150308,
      "grad_norm": 0.15600088238716125,
      "learning_rate": 1.715201139195443e-05,
      "loss": 1.6259,
      "step": 800
    },
    {
      "epoch": 0.16018510278544096,
      "grad_norm": 0.1694081872701645,
      "learning_rate": 1.6796012815948738e-05,
      "loss": 1.6253,
      "step": 900
    },
    {
      "epoch": 0.17798344753937884,
      "grad_norm": 0.166384756565094,
      "learning_rate": 1.644001423994304e-05,
      "loss": 1.6244,
      "step": 1000
    },
    {
      "epoch": 0.19578179229331671,
      "grad_norm": 0.1567460149526596,
      "learning_rate": 1.6084015663937345e-05,
      "loss": 1.6243,
      "step": 1100
    },
    {
      "epoch": 0.2135801370472546,
      "grad_norm": 0.1542542278766632,
      "learning_rate": 1.5728017087931648e-05,
      "loss": 1.6238,
      "step": 1200
    },
    {
      "epoch": 0.2313784818011925,
      "grad_norm": 0.1631898134946823,
      "learning_rate": 1.5372018511925955e-05,
      "loss": 1.6247,
      "step": 1300
    },
    {
      "epoch": 0.24917682655513038,
      "grad_norm": 0.16000622510910034,
      "learning_rate": 1.5016019935920258e-05,
      "loss": 1.6249,
      "step": 1400
    },
    {
      "epoch": 0.2669751713090683,
      "grad_norm": 0.16074591875076294,
      "learning_rate": 1.4660021359914563e-05,
      "loss": 1.6243,
      "step": 1500
    },
    {
      "epoch": 0.28477351606300616,
      "grad_norm": 0.17189988493919373,
      "learning_rate": 1.4304022783908866e-05,
      "loss": 1.6235,
      "step": 1600
    },
    {
      "epoch": 0.30257186081694404,
      "grad_norm": 0.17569391429424286,
      "learning_rate": 1.394802420790317e-05,
      "loss": 1.624,
      "step": 1700
    },
    {
      "epoch": 0.3203702055708819,
      "grad_norm": 0.17424029111862183,
      "learning_rate": 1.3592025631897475e-05,
      "loss": 1.6233,
      "step": 1800
    },
    {
      "epoch": 0.3381685503248198,
      "grad_norm": 0.1781511753797531,
      "learning_rate": 1.3236027055891778e-05,
      "loss": 1.624,
      "step": 1900
    },
    {
      "epoch": 0.3559668950787577,
      "grad_norm": 0.17189860343933105,
      "learning_rate": 1.2880028479886081e-05,
      "loss": 1.6242,
      "step": 2000
    },
    {
      "epoch": 0.37376523983269555,
      "grad_norm": 0.18621718883514404,
      "learning_rate": 1.2524029903880386e-05,
      "loss": 1.6231,
      "step": 2100
    },
    {
      "epoch": 0.39156358458663343,
      "grad_norm": 0.19683438539505005,
      "learning_rate": 1.216803132787469e-05,
      "loss": 1.6236,
      "step": 2200
    },
    {
      "epoch": 0.4093619293405713,
      "grad_norm": 0.18834000825881958,
      "learning_rate": 1.1812032751868994e-05,
      "loss": 1.6226,
      "step": 2300
    },
    {
      "epoch": 0.4271602740945092,
      "grad_norm": 0.19429908692836761,
      "learning_rate": 1.1456034175863298e-05,
      "loss": 1.6222,
      "step": 2400
    },
    {
      "epoch": 0.4449586188484471,
      "grad_norm": 0.20136727392673492,
      "learning_rate": 1.1100035599857601e-05,
      "loss": 1.623,
      "step": 2500
    },
    {
      "epoch": 0.462756963602385,
      "grad_norm": 0.1691955029964447,
      "learning_rate": 1.0744037023851906e-05,
      "loss": 1.6225,
      "step": 2600
    },
    {
      "epoch": 0.4805553083563229,
      "grad_norm": 0.1894056349992752,
      "learning_rate": 1.038803844784621e-05,
      "loss": 1.6229,
      "step": 2700
    },
    {
      "epoch": 0.49835365311026075,
      "grad_norm": 0.20506910979747772,
      "learning_rate": 1.0032039871840513e-05,
      "loss": 1.6227,
      "step": 2800
    },
    {
      "epoch": 0.5161519978641986,
      "grad_norm": 0.2124336212873459,
      "learning_rate": 9.676041295834818e-06,
      "loss": 1.6222,
      "step": 2900
    },
    {
      "epoch": 0.5339503426181366,
      "grad_norm": 0.23370251059532166,
      "learning_rate": 9.320042719829121e-06,
      "loss": 1.6234,
      "step": 3000
    },
    {
      "epoch": 0.5517486873720744,
      "grad_norm": 0.17544929683208466,
      "learning_rate": 8.964044143823424e-06,
      "loss": 1.6219,
      "step": 3100
    },
    {
      "epoch": 0.5695470321260123,
      "grad_norm": 0.18262793123722076,
      "learning_rate": 8.60804556781773e-06,
      "loss": 1.6228,
      "step": 3200
    },
    {
      "epoch": 0.5873453768799501,
      "grad_norm": 0.21238845586776733,
      "learning_rate": 8.252046991812034e-06,
      "loss": 1.6221,
      "step": 3300
    },
    {
      "epoch": 0.6051437216338881,
      "grad_norm": 0.17709317803382874,
      "learning_rate": 7.896048415806338e-06,
      "loss": 1.6226,
      "step": 3400
    },
    {
      "epoch": 0.6229420663878259,
      "grad_norm": 0.1797274649143219,
      "learning_rate": 7.540049839800642e-06,
      "loss": 1.6222,
      "step": 3500
    },
    {
      "epoch": 0.6407404111417638,
      "grad_norm": 0.2055772840976715,
      "learning_rate": 7.184051263794946e-06,
      "loss": 1.6235,
      "step": 3600
    },
    {
      "epoch": 0.6585387558957017,
      "grad_norm": 0.18800218403339386,
      "learning_rate": 6.828052687789249e-06,
      "loss": 1.6222,
      "step": 3700
    },
    {
      "epoch": 0.6763371006496396,
      "grad_norm": 0.20173931121826172,
      "learning_rate": 6.472054111783553e-06,
      "loss": 1.6217,
      "step": 3800
    },
    {
      "epoch": 0.6941354454035775,
      "grad_norm": 0.21066638827323914,
      "learning_rate": 6.116055535777857e-06,
      "loss": 1.623,
      "step": 3900
    },
    {
      "epoch": 0.7119337901575153,
      "grad_norm": 0.18991819024085999,
      "learning_rate": 5.7600569597721615e-06,
      "loss": 1.6222,
      "step": 4000
    },
    {
      "epoch": 0.7297321349114533,
      "grad_norm": 0.19671685993671417,
      "learning_rate": 5.404058383766465e-06,
      "loss": 1.6223,
      "step": 4100
    },
    {
      "epoch": 0.7475304796653911,
      "grad_norm": 0.19654816389083862,
      "learning_rate": 5.048059807760769e-06,
      "loss": 1.6223,
      "step": 4200
    },
    {
      "epoch": 0.765328824419329,
      "grad_norm": 0.21058300137519836,
      "learning_rate": 4.692061231755073e-06,
      "loss": 1.6224,
      "step": 4300
    },
    {
      "epoch": 0.7831271691732669,
      "grad_norm": 0.21490535140037537,
      "learning_rate": 4.336062655749377e-06,
      "loss": 1.6221,
      "step": 4400
    },
    {
      "epoch": 0.8009255139272048,
      "grad_norm": 0.1703457236289978,
      "learning_rate": 3.9800640797436814e-06,
      "loss": 1.6232,
      "step": 4500
    },
    {
      "epoch": 0.8187238586811426,
      "grad_norm": 0.2087615430355072,
      "learning_rate": 3.627625489498042e-06,
      "loss": 1.6223,
      "step": 4600
    },
    {
      "epoch": 0.8365222034350805,
      "grad_norm": 0.21675747632980347,
      "learning_rate": 3.271626913492346e-06,
      "loss": 1.6221,
      "step": 4700
    },
    {
      "epoch": 0.8543205481890184,
      "grad_norm": 0.19614320993423462,
      "learning_rate": 2.91562833748665e-06,
      "loss": 1.6226,
      "step": 4800
    },
    {
      "epoch": 0.8721188929429563,
      "grad_norm": 0.2110007107257843,
      "learning_rate": 2.5596297614809545e-06,
      "loss": 1.6219,
      "step": 4900
    },
    {
      "epoch": 0.8899172376968942,
      "grad_norm": 0.21793416142463684,
      "learning_rate": 2.2036311854752582e-06,
      "loss": 1.6227,
      "step": 5000
    },
    {
      "epoch": 0.9077155824508321,
      "grad_norm": 0.20519252121448517,
      "learning_rate": 1.8476326094695624e-06,
      "loss": 1.6226,
      "step": 5100
    },
    {
      "epoch": 0.92551392720477,
      "grad_norm": 0.19989648461341858,
      "learning_rate": 1.4916340334638663e-06,
      "loss": 1.6215,
      "step": 5200
    },
    {
      "epoch": 0.9433122719587078,
      "grad_norm": 0.21648351848125458,
      "learning_rate": 1.1356354574581702e-06,
      "loss": 1.6226,
      "step": 5300
    },
    {
      "epoch": 0.9611106167126457,
      "grad_norm": 0.19717930257320404,
      "learning_rate": 7.796368814524742e-07,
      "loss": 1.6225,
      "step": 5400
    },
    {
      "epoch": 0.9789089614665836,
      "grad_norm": 0.19538334012031555,
      "learning_rate": 4.2363830544677827e-07,
      "loss": 1.6227,
      "step": 5500
    },
    {
      "epoch": 0.9967073062205215,
      "grad_norm": 0.19405697286128998,
      "learning_rate": 6.763972944108224e-08,
      "loss": 1.6226,
      "step": 5600
    },
    {
      "epoch": 0.9999110082762304,
      "eval_runtime": 5.3753,
      "eval_samples_per_second": 930.188,
      "eval_steps_per_second": 29.208,
      "step": 5618
    }
  ],
  "logging_steps": 100,
  "max_steps": 5618,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2078379081326592.0,
  "train_batch_size": 12,
  "trial_name": null,
  "trial_params": null
}
